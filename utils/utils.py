import torch
def generate(model, tokenizer, input_ids, assistant_role_slice, gen_config=None):
    if gen_config is None:
        gen_config = model.generation_config
        gen_config.max_new_tokens = 128
    input_ids = input_ids[:assistant_role_slice.stop].to(model.device).unsqueeze(0)
    attn_masks = torch.ones_like(input_ids).to(model.device)
    print(f"input_ids_decoded: {tokenizer.decode(input_ids[0])}")
    output_ids = model.generate(input_ids,
                                attention_mask=attn_masks,
                                generation_config=gen_config,
                                pad_token_id=tokenizer.pad_token_id,
                                top_p=0.9,
                                do_sample=True,
                                temperature=0.7
                                )[0]
    return output_ids[assistant_role_slice.stop:]